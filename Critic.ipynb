{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "executed-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.nn.init import xavier_uniform_\n",
    "import numpy as scinp\n",
    "from pennylane import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "useful-orchestra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fantastic-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, data_dimension, hidden_dimensionality=None):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        if hidden_dimensionality is None:\n",
    "            hidden_dimensionality = [16, 8]\n",
    "\n",
    "        self.layer_dimensions = [data_dimension] + hidden_dimensionality + [1]\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        for i in range(len(self.layer_dimensions) - 1):\n",
    "            in_dim = self.layer_dimensions[i]\n",
    "            out_dim = self.layer_dimensions[i + 1]\n",
    "            linear_layer = nn.Linear(in_dim, out_dim)\n",
    "            xavier_uniform_(linear_layer.weight)\n",
    "            layers.append(linear_layer)\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        critic_output = self.network(x)\n",
    "        return critic_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "behavioral-alexander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (2): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic=Critic(4).to(device)\n",
    "critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "elect-logging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7185, 0.0412, 0.2561, 0.5148],\n",
       "        [0.1854, 0.8202, 0.8364, 0.7543],\n",
       "        [0.1910, 0.4498, 0.2355, 0.3210],\n",
       "        [0.4180, 0.8283, 0.9194, 0.8446]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_minibatch=torch.Tensor(4,4).uniform_(0,1).to(device)\n",
    "X_minibatch.requires_grad=True\n",
    "X_minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "scenic-lafayette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.0146, 0.0961, 0.1770, 0.2701], device='cuda:0'),)\n",
      "(tensor([0.0146, 0.0961, 0.1770, 0.2701], device='cuda:0'),)\n",
      "(tensor([0.0146, 0.0961, 0.1770, 0.2701], device='cuda:0'),)\n",
      "(tensor([0.0146, 0.0961, 0.1770, 0.2701], device='cuda:0'),)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_minibatch)):\n",
    "    X_i=X_minibatch[i]\n",
    "    y_i=critic(X_i)\n",
    "    print(torch.autograd.grad(outputs=y_i,inputs=X_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "vocational-today",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91235996, -0.32094347, -0.88413547,  0.74381247],\n",
       "       [ 0.96290347,  0.02159079,  0.17826059,  0.32000543],\n",
       "       [-0.19383135, -0.38087511, -0.95024166, -0.19886284],\n",
       "       [ 0.70306431,  0.41781422,  0.48008937, -0.79094579]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=scinp.random.uniform(-1,1,size=(4,4))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "graphic-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.91235996, -0.32094347, -0.88413547,  0.74381247],\n",
       "       [ 0.70306431,  0.41781422,  0.48008937, -0.79094579]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[[0,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "going-franchise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(B[np.random.choice(4,size=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "promising-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_arrays(X, batch_size, device):\n",
    "\n",
    "    # We sample n=batch_size points from the data\n",
    "    row_indices = np.random.choice(len(X), size=batch_size)\n",
    "    X_minibatch = X[row_indices]\n",
    "    X_minibatch = torch.Tensor(X_minibatch).to(device)\n",
    "\n",
    "    # We sample n=batch_size points from the generator\n",
    "    \n",
    "    row_indices = np.random.choice(len(X), size=batch_size)\n",
    "    z_minibatch = X[row_indices]\n",
    "    z_minibatch = torch.Tensor(z_minibatch).to(device)\n",
    "    \n",
    "    # We sample n=batch_size noise points\n",
    "    epsilons = torch.Tensor(batch_size).uniform_(0, 1).to(device)\n",
    "    return X_minibatch, z_minibatch, epsilons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "diagnostic-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minibatch, z_minibatch, epsilons=sample_arrays(B,2,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "sorted-bolivia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [10.]], device='cuda:0')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons=torch.Tensor(np.ones(2)*10).to(device)\n",
    "epsilons=epsilons[:,np.newaxis]\n",
    "epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "acceptable-livestock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0505,  0.3425,  1.0624, -0.4238],\n",
       "        [ 0.8969,  0.7987,  1.4303, -0.5921]], device='cuda:0')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=X_minibatch-z_minibatch\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "extended-wheel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5054,  3.4253, 10.6240, -4.2381],\n",
       "        [ 8.9690,  7.9869, 14.3033, -5.9208]], device='cuda:0')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "accepted-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21., 20.],\n",
       "        [35., 20.],\n",
       "        [ 7.,  0.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor([[3, 5],[5, 5],[1, 0]])                                                                                                                                                                          \n",
    "y = torch.Tensor([7,4])                                                                                                                                                                                   \n",
    "X*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-vision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
